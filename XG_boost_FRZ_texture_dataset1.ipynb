{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('ExtractedFeatures_standardized_InVitro_MonoB_Training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Mean', 'SD', 'Entropy', 'RMS', 'Kurtosis', 'Skewness', 'GLCM1',\n",
      "       'GLCM2', 'GLCM3', 'GLCM4', 'GLCM5', 'GLCM6', 'GLCM7', 'GLCM8', 'GLCM9',\n",
      "       'GLCM10', 'GLCM11', 'GLCM12', 'GLCM13', 'GLCM14', 'GLCM15', 'GLCM16',\n",
      "       'GLCM17', 'GLCM18', 'LBP1', 'LBP2', 'LBP3', 'LBP4', 'LBP5', 'LBP6',\n",
      "       'LBP7', 'LBP8', 'LBP9', 'LBP10', 'Label'],\n",
      "      dtype='object')\n",
      "(5000, 35)\n"
     ]
    }
   ],
   "source": [
    "print(data1.columns)\n",
    "print(data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>RMS</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>GLCM1</th>\n",
       "      <th>GLCM2</th>\n",
       "      <th>GLCM3</th>\n",
       "      <th>GLCM4</th>\n",
       "      <th>...</th>\n",
       "      <th>LBP1</th>\n",
       "      <th>LBP2</th>\n",
       "      <th>LBP3</th>\n",
       "      <th>LBP4</th>\n",
       "      <th>LBP5</th>\n",
       "      <th>LBP6</th>\n",
       "      <th>LBP7</th>\n",
       "      <th>LBP8</th>\n",
       "      <th>LBP9</th>\n",
       "      <th>LBP10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.032799</td>\n",
       "      <td>0.096077</td>\n",
       "      <td>0.081342</td>\n",
       "      <td>-0.082138</td>\n",
       "      <td>0.077215</td>\n",
       "      <td>0.081772</td>\n",
       "      <td>0.066670</td>\n",
       "      <td>0.062713</td>\n",
       "      <td>0.088863</td>\n",
       "      <td>0.076157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038476</td>\n",
       "      <td>-0.007739</td>\n",
       "      <td>-0.048717</td>\n",
       "      <td>0.023747</td>\n",
       "      <td>0.051774</td>\n",
       "      <td>0.015243</td>\n",
       "      <td>-0.040220</td>\n",
       "      <td>-0.094079</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>-0.046448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.999730</td>\n",
       "      <td>1.009528</td>\n",
       "      <td>0.994875</td>\n",
       "      <td>0.917837</td>\n",
       "      <td>1.031428</td>\n",
       "      <td>1.005400</td>\n",
       "      <td>1.017148</td>\n",
       "      <td>0.991063</td>\n",
       "      <td>0.975136</td>\n",
       "      <td>1.052608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969615</td>\n",
       "      <td>0.992469</td>\n",
       "      <td>1.015023</td>\n",
       "      <td>0.974649</td>\n",
       "      <td>0.983420</td>\n",
       "      <td>0.975271</td>\n",
       "      <td>0.924840</td>\n",
       "      <td>0.980025</td>\n",
       "      <td>0.978934</td>\n",
       "      <td>0.980524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.832218</td>\n",
       "      <td>-2.042955</td>\n",
       "      <td>-3.034173</td>\n",
       "      <td>-3.306187</td>\n",
       "      <td>-1.945913</td>\n",
       "      <td>-1.767257</td>\n",
       "      <td>-1.640993</td>\n",
       "      <td>-2.304767</td>\n",
       "      <td>-4.374324</td>\n",
       "      <td>-0.976784</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.140227</td>\n",
       "      <td>-9.563809</td>\n",
       "      <td>-9.135800</td>\n",
       "      <td>-4.096251</td>\n",
       "      <td>-3.524551</td>\n",
       "      <td>-4.508172</td>\n",
       "      <td>-5.256574</td>\n",
       "      <td>-9.751189</td>\n",
       "      <td>-4.236972</td>\n",
       "      <td>-5.603814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.618392</td>\n",
       "      <td>-0.610167</td>\n",
       "      <td>-0.552848</td>\n",
       "      <td>-0.745749</td>\n",
       "      <td>-0.486556</td>\n",
       "      <td>-0.641783</td>\n",
       "      <td>-0.670316</td>\n",
       "      <td>-0.677414</td>\n",
       "      <td>-0.478899</td>\n",
       "      <td>-0.417552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.732982</td>\n",
       "      <td>-0.601774</td>\n",
       "      <td>-0.705331</td>\n",
       "      <td>-0.608758</td>\n",
       "      <td>-0.640777</td>\n",
       "      <td>-0.626617</td>\n",
       "      <td>-0.655679</td>\n",
       "      <td>-0.676255</td>\n",
       "      <td>-0.719844</td>\n",
       "      <td>-0.776374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.042898</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.149770</td>\n",
       "      <td>-0.076598</td>\n",
       "      <td>-0.228184</td>\n",
       "      <td>-0.105066</td>\n",
       "      <td>-0.032270</td>\n",
       "      <td>0.126199</td>\n",
       "      <td>0.154992</td>\n",
       "      <td>-0.192368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216291</td>\n",
       "      <td>0.032746</td>\n",
       "      <td>-0.034089</td>\n",
       "      <td>0.185258</td>\n",
       "      <td>0.182568</td>\n",
       "      <td>0.112527</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>-0.063518</td>\n",
       "      <td>-0.116060</td>\n",
       "      <td>-0.171409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.674051</td>\n",
       "      <td>0.589582</td>\n",
       "      <td>0.702692</td>\n",
       "      <td>0.573872</td>\n",
       "      <td>0.438481</td>\n",
       "      <td>0.646096</td>\n",
       "      <td>0.580576</td>\n",
       "      <td>0.814994</td>\n",
       "      <td>0.679061</td>\n",
       "      <td>0.177285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671595</td>\n",
       "      <td>0.653298</td>\n",
       "      <td>0.621637</td>\n",
       "      <td>0.723739</td>\n",
       "      <td>0.779342</td>\n",
       "      <td>0.669787</td>\n",
       "      <td>0.612077</td>\n",
       "      <td>0.522758</td>\n",
       "      <td>0.744077</td>\n",
       "      <td>0.709266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.134343</td>\n",
       "      <td>5.785962</td>\n",
       "      <td>3.697522</td>\n",
       "      <td>2.842157</td>\n",
       "      <td>15.528410</td>\n",
       "      <td>8.745649</td>\n",
       "      <td>5.929200</td>\n",
       "      <td>3.516487</td>\n",
       "      <td>3.445425</td>\n",
       "      <td>14.118107</td>\n",
       "      <td>...</td>\n",
       "      <td>4.212088</td>\n",
       "      <td>2.867139</td>\n",
       "      <td>3.584903</td>\n",
       "      <td>2.994803</td>\n",
       "      <td>5.084974</td>\n",
       "      <td>4.575143</td>\n",
       "      <td>3.351600</td>\n",
       "      <td>3.814038</td>\n",
       "      <td>3.750347</td>\n",
       "      <td>3.596551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mean           SD      Entropy          RMS     Kurtosis  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean      0.032799     0.096077     0.081342    -0.082138     0.077215   \n",
       "std       0.999730     1.009528     0.994875     0.917837     1.031428   \n",
       "min      -2.832218    -2.042955    -3.034173    -3.306187    -1.945913   \n",
       "25%      -0.618392    -0.610167    -0.552848    -0.745749    -0.486556   \n",
       "50%       0.042898     0.006844     0.149770    -0.076598    -0.228184   \n",
       "75%       0.674051     0.589582     0.702692     0.573872     0.438481   \n",
       "max       5.134343     5.785962     3.697522     2.842157    15.528410   \n",
       "\n",
       "          Skewness        GLCM1        GLCM2        GLCM3        GLCM4  ...  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000  ...   \n",
       "mean      0.081772     0.066670     0.062713     0.088863     0.076157  ...   \n",
       "std       1.005400     1.017148     0.991063     0.975136     1.052608  ...   \n",
       "min      -1.767257    -1.640993    -2.304767    -4.374324    -0.976784  ...   \n",
       "25%      -0.641783    -0.670316    -0.677414    -0.478899    -0.417552  ...   \n",
       "50%      -0.105066    -0.032270     0.126199     0.154992    -0.192368  ...   \n",
       "75%       0.646096     0.580576     0.814994     0.679061     0.177285  ...   \n",
       "max       8.745649     5.929200     3.516487     3.445425    14.118107  ...   \n",
       "\n",
       "              LBP1         LBP2         LBP3         LBP4         LBP5  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean     -0.038476    -0.007739    -0.048717     0.023747     0.051774   \n",
       "std       0.969615     0.992469     1.015023     0.974649     0.983420   \n",
       "min      -4.140227    -9.563809    -9.135800    -4.096251    -3.524551   \n",
       "25%      -0.732982    -0.601774    -0.705331    -0.608758    -0.640777   \n",
       "50%      -0.216291     0.032746    -0.034089     0.185258     0.182568   \n",
       "75%       0.671595     0.653298     0.621637     0.723739     0.779342   \n",
       "max       4.212088     2.867139     3.584903     2.994803     5.084974   \n",
       "\n",
       "              LBP6         LBP7         LBP8         LBP9        LBP10  \n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000  \n",
       "mean      0.015243    -0.040220    -0.094079     0.019059    -0.046448  \n",
       "std       0.975271     0.924840     0.980025     0.978934     0.980524  \n",
       "min      -4.508172    -5.256574    -9.751189    -4.236972    -5.603814  \n",
       "25%      -0.626617    -0.655679    -0.676255    -0.719844    -0.776374  \n",
       "50%       0.112527     0.018800    -0.063518    -0.116060    -0.171409  \n",
       "75%       0.669787     0.612077     0.522758     0.744077     0.709266  \n",
       "max       4.575143     3.351600     3.814038     3.750347     3.596551  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>RMS</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>GLCM1</th>\n",
       "      <th>GLCM2</th>\n",
       "      <th>GLCM3</th>\n",
       "      <th>GLCM4</th>\n",
       "      <th>...</th>\n",
       "      <th>LBP2</th>\n",
       "      <th>LBP3</th>\n",
       "      <th>LBP4</th>\n",
       "      <th>LBP5</th>\n",
       "      <th>LBP6</th>\n",
       "      <th>LBP7</th>\n",
       "      <th>LBP8</th>\n",
       "      <th>LBP9</th>\n",
       "      <th>LBP10</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.030570</td>\n",
       "      <td>1.910645</td>\n",
       "      <td>1.763380</td>\n",
       "      <td>-1.106532</td>\n",
       "      <td>-0.298925</td>\n",
       "      <td>0.060138</td>\n",
       "      <td>2.136146</td>\n",
       "      <td>1.825162</td>\n",
       "      <td>0.959103</td>\n",
       "      <td>1.372025</td>\n",
       "      <td>...</td>\n",
       "      <td>1.352792</td>\n",
       "      <td>-0.229456</td>\n",
       "      <td>-0.285086</td>\n",
       "      <td>-0.252029</td>\n",
       "      <td>-1.501633</td>\n",
       "      <td>-1.486186</td>\n",
       "      <td>0.619805</td>\n",
       "      <td>0.904297</td>\n",
       "      <td>0.537212</td>\n",
       "      <td>HFB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.540950</td>\n",
       "      <td>2.035585</td>\n",
       "      <td>2.021876</td>\n",
       "      <td>-0.427589</td>\n",
       "      <td>0.021946</td>\n",
       "      <td>0.280804</td>\n",
       "      <td>2.467825</td>\n",
       "      <td>2.013120</td>\n",
       "      <td>1.186707</td>\n",
       "      <td>2.363135</td>\n",
       "      <td>...</td>\n",
       "      <td>1.440689</td>\n",
       "      <td>-1.398388</td>\n",
       "      <td>-0.342024</td>\n",
       "      <td>-0.594918</td>\n",
       "      <td>-1.067771</td>\n",
       "      <td>-1.290755</td>\n",
       "      <td>1.069021</td>\n",
       "      <td>0.654516</td>\n",
       "      <td>0.751853</td>\n",
       "      <td>HFB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.130183</td>\n",
       "      <td>2.011535</td>\n",
       "      <td>1.849540</td>\n",
       "      <td>-0.733343</td>\n",
       "      <td>0.807084</td>\n",
       "      <td>0.916084</td>\n",
       "      <td>2.192809</td>\n",
       "      <td>1.850896</td>\n",
       "      <td>1.290191</td>\n",
       "      <td>3.207098</td>\n",
       "      <td>...</td>\n",
       "      <td>1.236149</td>\n",
       "      <td>0.075863</td>\n",
       "      <td>-0.792273</td>\n",
       "      <td>-0.716795</td>\n",
       "      <td>-1.110095</td>\n",
       "      <td>-1.658564</td>\n",
       "      <td>1.554926</td>\n",
       "      <td>0.889386</td>\n",
       "      <td>0.798461</td>\n",
       "      <td>HFB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.971550</td>\n",
       "      <td>1.953266</td>\n",
       "      <td>1.775731</td>\n",
       "      <td>-0.842897</td>\n",
       "      <td>0.726709</td>\n",
       "      <td>0.988045</td>\n",
       "      <td>2.089074</td>\n",
       "      <td>1.889163</td>\n",
       "      <td>1.223390</td>\n",
       "      <td>2.992815</td>\n",
       "      <td>...</td>\n",
       "      <td>2.138237</td>\n",
       "      <td>0.183480</td>\n",
       "      <td>-0.713386</td>\n",
       "      <td>-0.542280</td>\n",
       "      <td>-1.392077</td>\n",
       "      <td>-1.344933</td>\n",
       "      <td>0.888508</td>\n",
       "      <td>0.793877</td>\n",
       "      <td>0.693045</td>\n",
       "      <td>HFB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.392299</td>\n",
       "      <td>0.166806</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>-2.024223</td>\n",
       "      <td>-0.593638</td>\n",
       "      <td>-0.207614</td>\n",
       "      <td>-0.130717</td>\n",
       "      <td>0.261630</td>\n",
       "      <td>-0.361021</td>\n",
       "      <td>-0.493872</td>\n",
       "      <td>...</td>\n",
       "      <td>1.736367</td>\n",
       "      <td>0.139826</td>\n",
       "      <td>-2.355790</td>\n",
       "      <td>-2.015931</td>\n",
       "      <td>-1.532237</td>\n",
       "      <td>-1.476702</td>\n",
       "      <td>-1.181700</td>\n",
       "      <td>2.344510</td>\n",
       "      <td>1.340334</td>\n",
       "      <td>HFB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mean        SD   Entropy       RMS  Kurtosis  Skewness     GLCM1  \\\n",
       "0  2.030570  1.910645  1.763380 -1.106532 -0.298925  0.060138  2.136146   \n",
       "1  2.540950  2.035585  2.021876 -0.427589  0.021946  0.280804  2.467825   \n",
       "2  2.130183  2.011535  1.849540 -0.733343  0.807084  0.916084  2.192809   \n",
       "3  1.971550  1.953266  1.775731 -0.842897  0.726709  0.988045  2.089074   \n",
       "4 -0.392299  0.166806  0.002802 -2.024223 -0.593638 -0.207614 -0.130717   \n",
       "\n",
       "      GLCM2     GLCM3     GLCM4  ...      LBP2      LBP3      LBP4      LBP5  \\\n",
       "0  1.825162  0.959103  1.372025  ...  1.352792 -0.229456 -0.285086 -0.252029   \n",
       "1  2.013120  1.186707  2.363135  ...  1.440689 -1.398388 -0.342024 -0.594918   \n",
       "2  1.850896  1.290191  3.207098  ...  1.236149  0.075863 -0.792273 -0.716795   \n",
       "3  1.889163  1.223390  2.992815  ...  2.138237  0.183480 -0.713386 -0.542280   \n",
       "4  0.261630 -0.361021 -0.493872  ...  1.736367  0.139826 -2.355790 -2.015931   \n",
       "\n",
       "       LBP6      LBP7      LBP8      LBP9     LBP10  Label  \n",
       "0 -1.501633 -1.486186  0.619805  0.904297  0.537212    HFB  \n",
       "1 -1.067771 -1.290755  1.069021  0.654516  0.751853    HFB  \n",
       "2 -1.110095 -1.658564  1.554926  0.889386  0.798461    HFB  \n",
       "3 -1.392077 -1.344933  0.888508  0.793877  0.693045    HFB  \n",
       "4 -1.532237 -1.476702 -1.181700  2.344510  1.340334    HFB  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cardinality_cols = [cname for cname in data1.columns if \n",
    "                                data1[cname].nunique() < 10] #and\n",
    "                                #X[cname].dtype == \"object\"]\n",
    "\n",
    "numeric_cols = [cname for cname in data1.columns if \n",
    "                                data1[cname].dtype in ['int64', 'float64']]\n",
    "#print(low_cardinality_cols)\n",
    "#print(numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "4995    4\n",
       "4996    4\n",
       "4997    4\n",
       "4998    4\n",
       "4999    4\n",
       "Length: 5000, dtype: int8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data1.drop('Label',axis=1)\n",
    "y = data1['Label']\n",
    "y1 = y.astype(\"category\").cat.codes\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y1,feature_names=X.columns)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.30, random_state=101)\n",
    "\n",
    "\n",
    "X_train = X #training data\n",
    "y_train = y1 #training label\n",
    "X_train\n",
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "995    4\n",
       "996    4\n",
       "997    4\n",
       "998    4\n",
       "999    4\n",
       "Length: 1000, dtype: int8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv('ExtractedFeatures_standardized_InVitro_MonoB_Testing.csv')\n",
    "X2 = data2.drop('Label',axis=1)\n",
    "y2 = data2['Label']\n",
    "y3 = y2.astype(\"category\").cat.codes\n",
    "data_dmatrix2 = xgb.DMatrix(data=X2,label=y3,feature_names=X2.columns)\n",
    "X_test = X2 #testing data\n",
    "y_test = y3 #testing label\n",
    "X_test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model: XGBoost, testing hyperparameters with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, score=0.469, total=   0.7s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, score=0.783, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, score=0.701, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, score=0.569, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, score=0.460, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=500 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=500, score=0.533, total=   2.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=500 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    4.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=500, score=0.841, total=   2.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=500 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    6.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=500, score=0.773, total=   2.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=500 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    8.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=500, score=0.703, total=   2.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=500 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   10.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=500, score=0.595, total=   2.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=1000, score=0.587, total=   4.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=1000, score=0.861, total=   4.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=1000, score=0.844, total=   4.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=1000, score=0.839, total=   4.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=1000, score=0.682, total=   4.0s\n",
      "[CV] learning_rate=0.01, max_depth=4, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=4, n_estimators=100, score=0.525, total=   1.2s\n",
      "[CV] learning_rate=0.01, max_depth=4, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=4, n_estimators=100, score=0.843, total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=4, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=4, n_estimators=100, score=0.835, total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=4, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=4, n_estimators=100, score=0.800, total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=4, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=4, n_estimators=100, score=0.668, total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=4, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=4, n_estimators=500, score=0.625, total=   5.9s\n",
      "[CV] learning_rate=0.01, max_depth=4, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=4, n_estimators=500, score=0.897, total=   5.9s\n",
      "[CV] learning_rate=0.01, max_depth=4, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=4, n_estimators=500, score=0.890, total=   6.0s\n",
      "[CV] learning_rate=0.01, max_depth=4, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=4, n_estimators=500, score=0.892, total=   6.4s\n",
      "[CV] learning_rate=0.01, max_depth=4, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=4, n_estimators=500, score=0.755, total=   6.3s\n",
      "[CV] learning_rate=0.01, max_depth=4, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=4, n_estimators=1000, score=0.713, total=  11.1s\n",
      "[CV] learning_rate=0.01, max_depth=4, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=4, n_estimators=1000, score=0.933, total=  11.7s\n",
      "[CV] learning_rate=0.01, max_depth=4, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=4, n_estimators=1000, score=0.914, total=  11.9s\n",
      "[CV] learning_rate=0.01, max_depth=4, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=4, n_estimators=1000, score=0.936, total=  12.1s\n",
      "[CV] learning_rate=0.01, max_depth=4, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=4, n_estimators=1000, score=0.795, total=  11.7s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=100, score=0.591, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=100, score=0.913, total=   3.5s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=100, score=0.857, total=   3.5s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=100, score=0.878, total=   3.7s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=100, score=0.788, total=   3.6s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=500, score=0.690, total=  14.5s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=500, score=0.932, total=  15.9s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=500, score=0.911, total=  15.7s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=500, score=0.943, total=  16.5s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=500, score=0.836, total=  16.2s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=1000, score=0.730, total=  24.8s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=1000, score=0.957, total=  27.7s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=1000, score=0.921, total=  27.7s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=1000, score=0.952, total=  28.0s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=1000, score=0.838, total=  28.0s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=100, score=0.540, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=100, score=0.843, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=100, score=0.777, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=100, score=0.709, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=100, score=0.589, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=500, score=0.675, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=500, score=0.923, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=500, score=0.901, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=500, score=0.925, total=   2.2s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=500, score=0.778, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=1000, score=0.726, total=   4.2s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=1000, score=0.957, total=   4.1s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=1000, score=0.929, total=   4.2s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=1000, score=0.941, total=   4.3s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=1000, score=0.818, total=   4.3s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=100, score=0.619, total=   1.2s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=100, score=0.893, total=   1.2s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=100, score=0.896, total=   1.2s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=100, score=0.895, total=   1.3s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=100, score=0.752, total=   1.3s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=500, score=0.752, total=   5.4s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=500, score=0.972, total=   5.6s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=500, score=0.927, total=   5.6s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=500, score=0.946, total=   5.7s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=500, score=0.827, total=   5.6s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=1000, score=0.755, total=   9.2s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=1000, score=0.980, total=  10.1s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=1000, score=0.932, total=  10.0s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=1000, score=0.945, total=  10.0s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=1000, score=0.832, total=   9.9s\n",
      "[CV] learning_rate=0.05, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=6, n_estimators=100, score=0.694, total=   2.9s\n",
      "[CV] learning_rate=0.05, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=6, n_estimators=100, score=0.941, total=   3.2s\n",
      "[CV] learning_rate=0.05, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=6, n_estimators=100, score=0.914, total=   3.2s\n",
      "[CV] learning_rate=0.05, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=6, n_estimators=100, score=0.943, total=   3.3s\n",
      "[CV] learning_rate=0.05, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=6, n_estimators=100, score=0.841, total=   3.2s\n",
      "[CV] learning_rate=0.05, max_depth=6, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=6, n_estimators=500, score=0.749, total=   8.8s\n",
      "[CV] learning_rate=0.05, max_depth=6, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=6, n_estimators=500, score=0.968, total=  10.2s\n",
      "[CV] learning_rate=0.05, max_depth=6, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=6, n_estimators=500, score=0.927, total=  10.4s\n",
      "[CV] learning_rate=0.05, max_depth=6, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=6, n_estimators=500, score=0.955, total=  10.3s\n",
      "[CV] learning_rate=0.05, max_depth=6, n_estimators=500 ...............\n",
      "[CV]  learning_rate=0.05, max_depth=6, n_estimators=500, score=0.845, total=  10.3s\n",
      "[CV] learning_rate=0.05, max_depth=6, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=6, n_estimators=1000, score=0.750, total=  11.8s\n",
      "[CV] learning_rate=0.05, max_depth=6, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=6, n_estimators=1000, score=0.972, total=  13.7s\n",
      "[CV] learning_rate=0.05, max_depth=6, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=6, n_estimators=1000, score=0.928, total=  13.8s\n",
      "[CV] learning_rate=0.05, max_depth=6, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=6, n_estimators=1000, score=0.952, total=  13.7s\n",
      "[CV] learning_rate=0.05, max_depth=6, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=6, n_estimators=1000, score=0.835, total=  13.7s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=100, score=0.589, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=100, score=0.863, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=100, score=0.843, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=100, score=0.845, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=100, score=0.678, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=500 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=500, score=0.726, total=   2.1s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=500 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=500, score=0.959, total=   2.1s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=500 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=500, score=0.929, total=   2.1s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=500 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=500, score=0.942, total=   2.1s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=500 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=500, score=0.813, total=   2.1s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=1000, score=0.751, total=   4.2s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=1000, score=0.976, total=   4.2s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=1000, score=0.934, total=   4.2s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=1000, score=0.949, total=   4.2s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=1000, score=0.826, total=   4.2s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=100, score=0.712, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=100, score=0.943, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=100, score=0.915, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=100, score=0.933, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=100, score=0.803, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=500 ................\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=500, score=0.752, total=   4.6s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=500 ................\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=500, score=0.980, total=   5.1s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=500 ................\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=500, score=0.930, total=   5.0s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=500 ................\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=500, score=0.946, total=   5.0s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=500 ................\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=500, score=0.831, total=   5.0s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=1000 ...............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=1000, score=0.754, total=   6.2s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=1000, score=0.980, total=   7.9s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=1000, score=0.930, total=   7.1s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=1000, score=0.937, total=   7.3s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=1000, score=0.831, total=   7.7s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.737, total=   2.5s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.966, total=   2.8s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.921, total=   3.3s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.946, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.848, total=   2.8s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=500 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=500, score=0.750, total=   5.9s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=500 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=500, score=0.974, total=   6.9s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=500 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=500, score=0.928, total=   7.2s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=500 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=500, score=0.948, total=   7.0s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=500 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=500, score=0.846, total=   7.0s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=1000, score=0.751, total=   7.5s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=1000, score=0.974, total=   8.8s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=1000, score=0.928, total=   8.6s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=1000, score=0.946, total=   8.7s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=1000, score=0.845, total=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 135 out of 135 | elapsed: 13.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8892\n",
      "{'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "xgb_model = xgb.XGBClassifier(tree_method='gpu_hist')\n",
    "clf = GridSearchCV(xgb_model, {'max_depth': [2,4, 6],\n",
    "                               'n_estimators': [100, 500,1000],\n",
    "                               'learning_rate': [ 0.01,0.05, 0.1] },\n",
    "                                verbose=10,n_jobs=1)\n",
    "\n",
    "training_start = time.perf_counter()\n",
    "clf.fit(X_train, y_train) \n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "training_end = time.perf_counter()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost's prediction accuracy is: 89.60\n"
     ]
    }
   ],
   "source": [
    "testing_start = time.perf_counter()\n",
    "preds = clf.best_estimator_.predict(X_test)\n",
    "testing_end = time.perf_counter()\n",
    "acc_xgb = (preds == y_test).sum().astype(float) / len(preds)*100\n",
    "print(\"XGBoost's prediction accuracy is: %3.2f\" % (acc_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each fold are: [0.75  0.974 0.928 0.948 0.846]\n",
      "Cross validation accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(clf.best_estimator_, X_train,y_train, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Cross validation accuracy: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Mean', 1: 'SD', 2: 'Entropy', 3: 'RMS', 4: 'Kurtosis', 5: 'Skewness', 6: 'GLCM1', 7: 'GLCM2', 8: 'GLCM3', 9: 'GLCM4', 10: 'GLCM5', 11: 'GLCM6', 12: 'GLCM7', 13: 'GLCM8', 14: 'GLCM9', 15: 'GLCM10', 16: 'GLCM11', 17: 'GLCM12', 18: 'GLCM13', 19: 'GLCM14', 20: 'GLCM15', 21: 'GLCM16', 22: 'GLCM17', 23: 'GLCM18', 24: 'LBP1', 25: 'LBP2', 26: 'LBP3', 27: 'LBP4', 28: 'LBP5', 29: 'LBP6', 30: 'LBP7', 31: 'LBP8', 32: 'LBP9', 33: 'LBP10'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create dict to use later\n",
    "myfeatures = X.columns\n",
    "dict_features = dict(enumerate(myfeatures))\n",
    "\n",
    "# feat importance with names f1,f2,...\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "axsub = xgb.plot_importance(clf.best_estimator_, max_num_features=10, ax=ax )\n",
    "\n",
    "# get the original names back\n",
    "Text_yticklabels = list(axsub.get_yticklabels())\n",
    "dict_features = dict(enumerate(myfeatures))\n",
    "lst_yticklabels = [ Text_yticklabels[i].get_text().lstrip('f') for i in range(len(Text_yticklabels))]\n",
    "#lst_yticklabels = [ dict_features[int(i)] for i in lst_yticklabels]\n",
    "\n",
    "axsub.set_yticklabels(lst_yticklabels)\n",
    "print(dict_features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       200\n",
      "           1       0.85      0.79      0.82       200\n",
      "           2       0.87      0.99      0.93       200\n",
      "           3       0.95      0.80      0.87       200\n",
      "           4       0.95      0.94      0.94       200\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.89      1000\n",
      "weighted avg       0.90      0.90      0.89      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "#fig, ax = plt.subplots(figsize=(10,10))\n",
    "#cmp = sklearn.metrics.ConfusionMatrixDisplay.from_predictions(y_test,preds, normalize = 'true', cmap = 'Blues',ax=ax)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[193   0   1   2   4]\n",
      " [  6 157  28   7   2]\n",
      " [  0   1 199   0   0]\n",
      " [ 10  27   0 160   3]\n",
      " [ 13   0   0   0 187]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1513.1357467\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# declare parameters\n",
    "params = {\n",
    "            'objective':'binary:logistic',\n",
    "            'max_depth': 4,\n",
    "            'alpha': 10,\n",
    "            'learning_rate': 1.0,\n",
    "            'n_estimators':100\n",
    "        }         \n",
    "           \n",
    "       \n",
    "# instantiate the classifier \n",
    "xgb_clf = XGBClassifier(**params)\n",
    "\n",
    "training_start = time.perf_counter()\n",
    "# fit the classifier to the training data\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "training_end = time.perf_counter()\n",
    "print(training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on float object:\n",
      "\n",
      "class float(object)\n",
      " |  float(x=0, /)\n",
      " |  \n",
      " |  Convert a string or number to a floating point number, if possible.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __abs__(self, /)\n",
      " |      abs(self)\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __bool__(self, /)\n",
      " |      self != 0\n",
      " |  \n",
      " |  __divmod__(self, value, /)\n",
      " |      Return divmod(self, value).\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __float__(self, /)\n",
      " |      float(self)\n",
      " |  \n",
      " |  __floordiv__(self, value, /)\n",
      " |      Return self//value.\n",
      " |  \n",
      " |  __format__(self, format_spec, /)\n",
      " |      Formats the float according to format_spec.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getnewargs__(self, /)\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __int__(self, /)\n",
      " |      int(self)\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, value, /)\n",
      " |      Return self%value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __neg__(self, /)\n",
      " |      -self\n",
      " |  \n",
      " |  __pos__(self, /)\n",
      " |      +self\n",
      " |  \n",
      " |  __pow__(self, value, mod=None, /)\n",
      " |      Return pow(self, value, mod).\n",
      " |  \n",
      " |  __radd__(self, value, /)\n",
      " |      Return value+self.\n",
      " |  \n",
      " |  __rdivmod__(self, value, /)\n",
      " |      Return divmod(value, self).\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rfloordiv__(self, value, /)\n",
      " |      Return value//self.\n",
      " |  \n",
      " |  __rmod__(self, value, /)\n",
      " |      Return value%self.\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  __round__(self, ndigits=None, /)\n",
      " |      Return the Integral closest to x, rounding half toward even.\n",
      " |      \n",
      " |      When an argument is passed, work like built-in round(x, ndigits).\n",
      " |  \n",
      " |  __rpow__(self, value, mod=None, /)\n",
      " |      Return pow(value, self, mod).\n",
      " |  \n",
      " |  __rsub__(self, value, /)\n",
      " |      Return value-self.\n",
      " |  \n",
      " |  __rtruediv__(self, value, /)\n",
      " |      Return value/self.\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  __sub__(self, value, /)\n",
      " |      Return self-value.\n",
      " |  \n",
      " |  __truediv__(self, value, /)\n",
      " |      Return self/value.\n",
      " |  \n",
      " |  __trunc__(self, /)\n",
      " |      Return the Integral closest to x between 0 and x.\n",
      " |  \n",
      " |  as_integer_ratio(self, /)\n",
      " |      Return integer ratio.\n",
      " |      \n",
      " |      Return a pair of integers, whose ratio is exactly equal to the original float\n",
      " |      and with a positive denominator.\n",
      " |      \n",
      " |      Raise OverflowError on infinities and a ValueError on NaNs.\n",
      " |      \n",
      " |      >>> (10.0).as_integer_ratio()\n",
      " |      (10, 1)\n",
      " |      >>> (0.0).as_integer_ratio()\n",
      " |      (0, 1)\n",
      " |      >>> (-.25).as_integer_ratio()\n",
      " |      (-1, 4)\n",
      " |  \n",
      " |  conjugate(self, /)\n",
      " |      Return self, the complex conjugate of any float.\n",
      " |  \n",
      " |  hex(self, /)\n",
      " |      Return a hexadecimal representation of a floating-point number.\n",
      " |      \n",
      " |      >>> (-0.1).hex()\n",
      " |      '-0x1.999999999999ap-4'\n",
      " |      >>> 3.14159.hex()\n",
      " |      '0x1.921f9f01b866ep+1'\n",
      " |  \n",
      " |  is_integer(self, /)\n",
      " |      Return True if the float is an integer.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  __getformat__(typestr, /) from builtins.type\n",
      " |      You probably don't want to use this function.\n",
      " |      \n",
      " |        typestr\n",
      " |          Must be 'double' or 'float'.\n",
      " |      \n",
      " |      It exists mainly to be used in Python's test suite.\n",
      " |      \n",
      " |      This function returns whichever of 'unknown', 'IEEE, big-endian' or 'IEEE,\n",
      " |      little-endian' best describes the format of floating point numbers used by the\n",
      " |      C type named by typestr.\n",
      " |  \n",
      " |  __set_format__(typestr, fmt, /) from builtins.type\n",
      " |      You probably don't want to use this function.\n",
      " |      \n",
      " |        typestr\n",
      " |          Must be 'double' or 'float'.\n",
      " |        fmt\n",
      " |          Must be one of 'unknown', 'IEEE, big-endian' or 'IEEE, little-endian',\n",
      " |          and in addition can only be one of the latter two if it appears to\n",
      " |          match the underlying C reality.\n",
      " |      \n",
      " |      It exists mainly to be used in Python's test suite.\n",
      " |      \n",
      " |      Override the automatic determination of C-level floating point type.\n",
      " |      This affects how floats are converted to and from binary strings.\n",
      " |  \n",
      " |  fromhex(string, /) from builtins.type\n",
      " |      Create a floating-point number from a hexadecimal string.\n",
      " |      \n",
      " |      >>> float.fromhex('0x1.ffffp10')\n",
      " |      2047.984375\n",
      " |      >>> float.fromhex('-0x1p-1074')\n",
      " |      -5e-324\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  imag\n",
      " |      the imaginary part of a complex number\n",
      " |  \n",
      " |  real\n",
      " |      the real part of a complex number\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost's prediction accuracy is: 87.10\n",
      "1520.9122805\n"
     ]
    }
   ],
   "source": [
    "testing_start = time.perf_counter()\n",
    "preds = xgb_clf.predict(X_test)\n",
    "testing_end = time.perf_counter()\n",
    "acc_xgb = (preds == y_test).sum().astype(float) / len(preds)*100\n",
    "print(\"XGBoost's prediction accuracy is: %3.2f\" % (acc_xgb))\n",
    "print(testing_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each fold are: [0.662 0.923 0.898 0.877 0.781]\n",
      "Cross validation accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(xgb_clf, X_train,y_train, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Cross validation accuracy: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94       200\n",
      "           1       0.80      0.69      0.74       200\n",
      "           2       0.85      0.98      0.91       200\n",
      "           3       0.85      0.74      0.79       200\n",
      "           4       0.92      0.98      0.95       200\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.87      0.87      0.87      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
